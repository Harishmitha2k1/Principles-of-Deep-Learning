{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2a8601",
   "metadata": {},
   "source": [
    "### Part-I: Design OR gate using the concept of Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6c0e34",
   "metadata": {},
   "source": [
    "Step1: Define helper functions\n",
    "\n",
    "You can implement gate operations by identifying the appropriate weights\n",
    "for w1 and w2 and bias b for the single neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38053ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def logic_gate(w1, w2, b):\n",
    "    # Helper to create logic gate functions\n",
    "    # Plug in values for weight_a, weight_b, and bias\n",
    "    #return lambda x1, x2: sigmoid(w1 * x1 + w2 * x2 + b)\n",
    "\n",
    "#def test(gate):\n",
    "    # Helper function to test out our weight functions.\n",
    "    #for a, b in (0, 0), (0, 1), (1, 0), (1, 1):\n",
    "        #print(\"{}, {}: {}\".format(a, b, np.round(gate(a,b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a03cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c155b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    s=1/(1+math.exp(-x))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f28cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logic_gate(w1,w2,b):\n",
    "    return lambda x1,x2: sigmoid(w1*x1+w2*x2+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc650da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(gate):\n",
    "    for a,b in (0,0),(0,1),(1,0),(1,1):\n",
    "        print(\"{},{}: {}\".format(a,b,np.round(gate(a,b))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8754358a",
   "metadata": {},
   "source": [
    "Step2: Identify values for weights, w1 and w2 and bias, b, for OR gate.Then, call logic_gate() function first with the values of weights and bias and test the outputs. For example, do the following steps and verify OR gate operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "683d7c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#or_gate = logic_gate(20, 20, -10)\n",
    "#test(or_gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bfca2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,0: 0.0\n",
      "0,1: 1.0\n",
      "1,0: 1.0\n",
      "1,1: 1.0\n"
     ]
    }
   ],
   "source": [
    "or_gate = logic_gate(20, 20, -10)\n",
    "test(or_gate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479a4eae",
   "metadata": {},
   "source": [
    "### Part-II: Implement the operations of AND, NOR and NAND gates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9228d310",
   "metadata": {},
   "source": [
    "Step1: Identify values for weights, w1 and w2 and bias, b, for AND gate.\n",
    "Then, call logic_gate() function first with the values of weights and bias and\n",
    "test the outputs. Draw manually using pen the diagram of OR gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56402c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,0: 0.0\n",
      "0,1: 0.0\n",
      "1,0: 0.0\n",
      "1,1: 1.0\n"
     ]
    }
   ],
   "source": [
    "and_gate = logic_gate(10, 10, -10)\n",
    "test(and_gate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60632833",
   "metadata": {},
   "source": [
    "Step2: Identify values for weights, w1 and w2 and bias, b, for NOR gate.\n",
    "Then, call logic_gate() function first with the values of weights and bias and\n",
    "test the outputs. Draw manually using pen the diagram of NOR gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc047bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,0: 1.0\n",
      "0,1: 0.0\n",
      "1,0: 0.0\n",
      "1,1: 0.0\n"
     ]
    }
   ],
   "source": [
    "nor_gate = logic_gate(-20,-20,10)\n",
    "test(nor_gate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bd9f01",
   "metadata": {},
   "source": [
    "Step3: Identify values for weights, w1 and w2 and bias, b, for NAND gate.\n",
    "Then, call logic_gate() function first with the values of weights and bias and\n",
    "test the outputs. Draw manually using pen the diagram of NAND gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21fe47a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,0: 1.0\n",
      "0,1: 1.0\n",
      "1,0: 1.0\n",
      "1,1: 0.0\n"
     ]
    }
   ],
   "source": [
    "nand_gate = logic_gate(-1,-1,2)\n",
    "test(nand_gate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821f8aae",
   "metadata": {},
   "source": [
    "### Part-III: Limitations of single neuron for XOR operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba7e7db",
   "metadata": {},
   "source": [
    "Can you identify a set of weights such that a single neuron can output the values for XOR gate?. Single neurons can't correlate inputs, so it's just\n",
    "confused. So individual neurons are out. Can we still use neurons to\n",
    "somehow form an XOR gate?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c793f25d",
   "metadata": {},
   "source": [
    "Here, we've got the inputs going to two separate gates: the top neuron is\n",
    "an OR gate, and the bottom is a NAND gate. The output of these gates then\n",
    "get passed to another neuron, which is an AND gate. If you work out the\n",
    "outputs at each combination of input values, you'll see that this is an XOR\n",
    "gate!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31833836",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,0: 0.0\n",
      "0,1: 1.0\n",
      "1,0: 1.0\n",
      "1,1: 1.0\n"
     ]
    }
   ],
   "source": [
    "def xor_gate(a,b):\n",
    "    c=or_gate(a,b)\n",
    "    d=nand_gate(a,b)\n",
    "    return and_gate(c,d)\n",
    "test(xor_gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a441c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR Gate truth table \n",
      "\n",
      "X, Y X+Y\n",
      "0.0, 1.0: 0.0\n",
      "1.0, 1.0: 1.0\n",
      "1.0, 1.0: 1.0\n",
      "1.0, 0.0: 0.0\n"
     ]
    }
   ],
   "source": [
    "def logic_gate(w1, W2, b):\n",
    "    return lambda x1, x2: sigmoid(w1 * x1 + W2 * x2 + b)\n",
    "\n",
    "def final(gate):\n",
    "    for a, b in zip(result1, result2):\n",
    "        print(\"{}, {}: {}\".format(a, b, np.round(gate(a, b))))\n",
    "result1 = []\n",
    "result2 = []\n",
    "\n",
    "or_gate = logic_gate(20,20,-10)\n",
    "for a, b in (0, 0), (0, 1), (1, 0), (1, 1):\n",
    "    result1.append(np.round(or_gate(a,b)))\n",
    "\n",
    "nand_gate = logic_gate(-23,-25,35)\n",
    "for a, b in (0, 0), (0, 1), (1, 0), (1, 1):\n",
    "    result2.append(np.round(nand_gate(a,b)))\n",
    "\n",
    "xor_gate = logic_gate(20,20,-30)\n",
    "print(\"XOR Gate truth table \\n\")\n",
    "print(\"X, Y X+Y\")\n",
    "final(xor_gate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5068d45",
   "metadata": {},
   "source": [
    "### Part-IV: Logic Gates using Keras library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937c4fae",
   "metadata": {},
   "source": [
    "In this part of the lab, you will create and implement the operations of logic\n",
    "gates such as AND, OR, NOT, NAND, NOR and XOR in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e1bd7",
   "metadata": {},
   "source": [
    "Steps: For each logic gate operations\n",
    "1. Create a tensor using Numpy array for input values and output\n",
    "values\n",
    "2. Create a neural network with one hidden layer with 16 nodes, input\n",
    "dimensions to be 2 and “relu” activation function. The output layer\n",
    "should have one node with sigmoid activation function.\n",
    "3. Compile the model with “adam” optimizer, 'mean_squared_error' loss\n",
    "function and 'binary_accuracy' as performance or metric.\n",
    "4. Run the model with 100 epoch and predict the output values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f56184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e44038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AND gate\n",
    "# the four different states of the AND gate\n",
    "training_data = np.array([[0,0],[0,1],[1,0],[1,1]], \"float32\")\n",
    "# the four expected results in the same order\n",
    "target_data = np.array([[0],[0],[0],[1]], \"float32\")\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "optimizer='adam',\n",
    "metrics=['binary_accuracy'])\n",
    "model.fit(training_data, target_data, epochs=100, verbose=2)\n",
    "print(model.predict(training_data).round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a478e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR gate\n",
    "# the four different states of the OR gate\n",
    "training_data = np.array([[0,0],[0,1],[1,0],[1,1]], \"float32\")\n",
    "# the four expected results in the same order\n",
    "target_data = np.array([[0],[1],[1],[1]], \"float32\")\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "optimizer='adam',\n",
    "metrics=['binary_accuracy'])\n",
    "model.fit(training_data, target_data, epochs=100, verbose=2)\n",
    "print(model.predict(training_data).round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192df455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT gate\n",
    "# the four different states of the NOT gate\n",
    "training_data = np.array([[0],[1]], \"float32\")\n",
    "# the four expected results in the same order\n",
    "target_data = np.array([[1],[0]], \"float32\")\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=1, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "optimizer='adam',\n",
    "metrics=['binary_accuracy'])\n",
    "model.fit(training_data, target_data, epochs=100, verbose=2)\n",
    "print(model.predict(training_data).round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb9fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NAND gate\n",
    "# the four different states of the NAND gate\n",
    "training_data = np.array([[0,0],[0,1],[1,0],[1,1]], \"float32\")\n",
    "# the four expected results in the same order\n",
    "target_data = np.array([[1],[1],[1],[0]], \"float32\")\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "optimizer='adam',\n",
    "metrics=['binary_accuracy'])\n",
    "model.fit(training_data, target_data, epochs=100, verbose=2)\n",
    "print(model.predict(training_data).round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1cfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOR gate\n",
    "# the four different states of the NOR gate\n",
    "training_data = np.array([[0,0],[0,1],[1,0],[1,1]], \"float32\")\n",
    "# the four expected results in the same order\n",
    "target_data = np.array([[1],[0],[0],[0]], \"float32\")\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "optimizer='adam',\n",
    "metrics=['binary_accuracy'])\n",
    "model.fit(training_data, target_data, epochs=100, verbose=2)\n",
    "print(model.predict(training_data).round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292dc599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XOR gate\n",
    "# the four different states of the XOR gate\n",
    "training_data = np.array([[0,0],[0,1],[1,0],[1,1]], \"float32\")\n",
    "# the four expected results in the same order\n",
    "target_data = np.array([[0],[1],[1],[0]], \"float32\")\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=2, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',\n",
    "optimizer='adam',\n",
    "metrics=['binary_accuracy'])\n",
    "model.fit(training_data, target_data, epochs=100, verbose=2)\n",
    "print(model.predict(training_data).round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3ecbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
